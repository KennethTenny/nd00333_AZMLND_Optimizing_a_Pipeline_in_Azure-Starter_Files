{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1598275788035
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: kenneth-workspace\n",
      "Azure region: eastus\n",
      "Subscription id: 7f96438t-1br7-4xn5-892k-3155er1zt569\n",
      "Resource group: Udacity\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "\n",
    "ws = Workspace.get(name=\"kenneth-workspace\")\n",
    "exp = Experiment(workspace=ws, name=\"kenneth-project\")\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "run = exp.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1598275788675
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "\n",
    "cluster = \"kenneth-cluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster)\n",
    "    print('Existing Cluster found')\n",
    "except Exception as e:\n",
    "    print(e + \"No existing cluster found. Creating a new cluster.\")\n",
    "    config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', max_nodes=4, vm_priority='lowpriority',\n",
    "                                                           idle_seconds_before_scaledown=600)\n",
    "    compute_target = ComputeTarget.create(ws, cluster, config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1598275789986
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform\n",
    "\n",
    "\n",
    "\n",
    "ps = RandomParameterSampling(parameter_space={'C': uniform(0.1, 100)})\n",
    "\n",
    "policy = BanditPolicy(slack_factor=0.1)\n",
    "\n",
    "est = SKLearn(source_directory='./train', entry_script='train.py', compute_target=compute_target,\n",
    "                script_params={ '--C' : 1, '--max_iter': 50})\n",
    "\n",
    "\n",
    "hyperdrive_config = HyperDriveConfig(hyperparameter_sampling=ps, primary_metric_name='Accuracy', \n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, max_total_runs=4, \n",
    "                                     max_duration_minutes=7, est=est, policy=policy)\n",
    "                            \n",
    "# if \"training\" not in os.listdir():\n",
    "#     os.mkdir(\"./training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "experiment = Experiment(ws, \"kenneth-experiment\")\n",
    "run = experiment.submit(config=hyperdrive_config, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1598276310862
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "best_run = run.get_best_run_by_primary_metric()\n",
    "best_run.download_files(prefix='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "\n",
    "data_url = \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
    "data = TabularDatasetFactory.from_delimited_files(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1598275726969
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('train')\n",
    "from train import clean_data\n",
    "\n",
    "x, y = clean_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "training_data = np.concatenate((x_train, y_train[:, np.newaxis]), axis=-1)\n",
    "training_dataframe = pd.DataFrame(data=training_data, columns=x.columns.to_list() + ['y'])\n",
    "training_dataframe.to_csv('kenneth.csv', index=False)\n",
    "\n",
    "\n",
    "subscription_id = '7f96438t-1br7-4xn5-892k-3155er1zt569'\n",
    "resource_group = 'Udacity'\n",
    "workspace_name = 'kenneth-workspace'\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "\n",
    "training_data = Dataset.get_by_name(workspace, name='kenneth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gather": {
     "logged": 1598275665403
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['norm_macro_recall',\n",
       " 'precision_score_weighted',\n",
       " 'average_precision_score_weighted',\n",
       " 'AUC_weighted',\n",
       " 'accuracy']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import azureml.train.automl.utilities\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "azureml.train.automl.utilities.get_primary_metrics('classification')\n",
    "\n",
    "config = AutoMLConfig(\n",
    "    label_column_name='y',\n",
    "    task='classification',\n",
    "    primary_metric='AUC_weighted',\n",
    "    experiment_timeout_minutes=15,\n",
    "    training_data=training_data,\n",
    "    n_cross_validations=4\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_4ke630v5-67b7-49rt-826n-80j2h8va30s5\n",
      "\n",
      "Current status: DatasetEvaluation. Gathering dataset statistics.\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\n",
      "Current status: DatasetFeaturizationCompleted. Completed fit featurizers and featurizing the dataset.\n",
      "Current status: DatasetBalancing. Performing class balancing sweeping\n",
      "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Class balancing detection\n",
      "STATUS:       ALERTED\n",
      "DESCRIPTION:  To decrease model bias, please cancel the current run and fix balancing problem.\n",
      "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
      "DETAILS:      Imbalanced data can lead to a falsely perceived positive effect of a model's accuracy because the input data has bias towards one class.\n",
      "+---------------------------------+---------------------------------+--------------------------------------+\n",
      "|Size of the smallest class       |Name/Label of the smallest class |Number of samples in the training data|\n",
      "+=================================+=================================+======================================+\n",
      "|1243                             |1.0                              |21451                                 |\n",
      "+---------------------------------+---------------------------------+--------------------------------------+\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         Missing feature values imputation\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  No feature missing values were detected in the training data.\n",
      "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
      "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   MaxAbsScaler LightGBM                          0:00:29       0.9480    0.9480\n",
      "         1   MaxAbsScaler XGBoostClassifier                 0:00:26       0.9410    0.9480\n",
      "         2   MinMaxScaler RandomForest                      0:00:27       0.9205    0.9480\n",
      "         3   StandardScalerWrapper SGD                      0:00:27       0.9201    0.9480\n",
      "         4   MinMaxScaler SGD                               0:00:24       0.9145    0.9480\n",
      "         5   StandardScalerWrapper RandomForest             0:00:24       0.9139    0.9480\n",
      "         6   MaxAbsScaler SGD                               0:00:24       0.9126    0.9480\n",
      "         7   MaxAbsScaler ExtremeRandomTrees                0:00:24       0.9092    0.9480\n",
      "         8   StandardScalerWrapper SGD                      0:00:24       0.9091    0.9480\n",
      "         9   MinMaxScaler ExtremeRandomTrees                0:00:24       0.9054    0.9480\n",
      "        10   StandardScalerWrapper SGD                      0:00:37       0.9216    0.9480\n",
      "        11   MinMaxScaler SGD                               0:00:36       0.9285    0.9480\n",
      "        12   RobustScaler ExtremeRandomTrees                0:00:41       0.7995    0.9480\n",
      "        13   MaxAbsScaler RandomForest                      0:00:31       0.9198    0.9480\n",
      "        14   MaxAbsScaler SGD                               0:00:32       0.9106    0.9480\n",
      "        15   StandardScalerWrapper SGD                      0:00:27       0.9186    0.9480\n",
      "        16   MinMaxScaler RandomForest                      0:00:27       0.9086    0.9480\n",
      "        17   StandardScalerWrapper SGD                      0:00:27       0.9292    0.9480\n",
      "        18   MinMaxScaler SGD                               0:00:24       0.9277    0.9480\n",
      "        19   StandardScalerWrapper SGD                      0:00:21       0.9263    0.9480\n",
      "        20   RobustScaler ExtremeRandomTrees                0:00:27       0.8548    0.9480\n",
      "        21   MaxAbsScaler ExtremeRandomTrees                0:00:24       0.8358    0.9480\n",
      "        22   SparseNormalizer SVM                           0:07:07       0.9245    0.9480\n",
      "        23   VotingEnsemble                                 0:00:52       0.9485    0.9485\n",
      "        24   StackEnsemble                                  0:00:57       0.9452    0.9485\n",
      "Stopping criteria reached at iteration 25. Ending experiment.\n",
      "****************************************************************************************************\n",
      "Current status: BestRunExplainModel. Best run model explanations started\n",
      "Current status: ModelExplanationDataSetSetup. Model explanations data setup completed\n",
      "Current status: PickSurrogateModel. Choosing LightGBM as the surrogate model for explanations\n",
      "Current status: EngineeredFeatureExplanations. Computation of engineered features started\n",
      "Current status: EngineeredFeatureExplanations. Computation of engineered features completed\n",
      "Current status: BestRunExplainModel. Best run model explanations completed\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(ws, \"kenneth-experiment-2\")\n",
    "run = experiment.submit(config=config, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ , model = run.get_output()\n",
    "returned_output = joblib.dump(model, 'best_automl_model.joblib')\n",
    "\n",
    "try:\n",
    "    compute_target.delete()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
